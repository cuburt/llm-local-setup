{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58303dbb-09e0-44ee-9b11-1d597be5c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Downloading protobuf-4.25.2-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-4.25.2\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5e150f-f5c4-44c9-96a6-6452d0c28ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuburtbalanon/anaconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, CodeLlamaTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "hf_auth = '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'\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./models/codellama-7b-instruct.Q5_K_M.gguf\", model_type=\"llama\", gpu_layers=150, context_length=256, hf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32544fa-a9f3-42aa-a321-072a4e81bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CodeLlamaTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7aff57-1eb9-4938-b03b-96f19e4faaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='text-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2021819e-5fb2-4690-b87a-8ac5dcb07eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"generate a python code for printing 'Hello World'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83606c67-942c-4b3d-9f22-ffcf6ebb2429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (257) exceeded maximum context length (256).\n",
      "Number of tokens (258) exceeded maximum context length (256).\n",
      "Number of tokens (259) exceeded maximum context length (256).\n",
      "Number of tokens (260) exceeded maximum context length (256).\n",
      "Number of tokens (261) exceeded maximum context length (256).\n",
      "Number of tokens (262) exceeded maximum context length (256).\n",
      "Number of tokens (263) exceeded maximum context length (256).\n",
      "Number of tokens (264) exceeded maximum context length (256).\n",
      "Number of tokens (265) exceeded maximum context length (256).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate a python code for printing 'Hello World' in a file.\n",
      "\n",
      "\\begin{code}\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "I want to generate a python code for printing 'Hello World' in a file.\n",
      "\n",
      "\\begin{code}\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "I want to generate a python code for printing 'Hello World' in a file.\n",
      "\n",
      "\\begin{code}\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "I want to generate a python code for printing 'Hello World' in a file.\n",
      "\n",
      "\\begin{code}\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    print(\"Hello World\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\\end{code}\n",
      "\n",
      "I want to generate a python code for printing 'Hello World code for printing 'Hello\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt, max_new_tokens=256)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11b250-7acf-4e81-8b1f-5040e976be8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
